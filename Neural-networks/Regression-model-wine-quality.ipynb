{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k2lfHSCY6afB"
   },
   "source": [
    "**Regression**\n",
    "\n",
    "Regression models are typically used to predict one value (or a set of values) based on input data. Let's say for example: Predict the price of a car based on the year, fuel consumption, type (sports, compact, SUV), motor power. Or predict the number of sales of a specific product based on month of the year, product price, local economy situation. \n",
    "\n",
    "This is a supervised learning statistical model that correlates the influence of independent variables on dependent variables through fitting a mathematical function according to the behavior of the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 45080,
     "status": "ok",
     "timestamp": 1574499444653,
     "user": {
      "displayName": "Cristian Bortolini Ferreira",
      "photoUrl": "",
      "userId": "01183676841716453456"
     },
     "user_tz": -60
    },
    "id": "wpefszoB-gkd",
    "outputId": "dc879642-a25b-4b5b-9e89-5d3a46b83f18"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.layers import Dense, Input\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7W2mmiMtA8FH"
   },
   "source": [
    "**Introducing new Libraries**\n",
    "\n",
    "* **pandas**: Library offering data structures and operation for data manipulation and analysis.\n",
    "\n",
    "* **sklearn**: Library providing machine learning algorithms and tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7W2mmiMtA8FH"
   },
   "source": [
    "**The Data**\n",
    "\n",
    "We are going to be using a dataset about wine quality. The input variables will give us information about the wine like pH and alcohol percentage. The output variable correlates these inputs to the wine quality.\n",
    "\n",
    "This time, the data is not well organized and is inside a csv file. We are going to read this file and prepare the data for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Columns: ['type' 'fixed acidity' 'volatile acidity' 'citric acid' 'residual sugar'\n",
      " 'chlorides' 'free sulfur dioxide' 'total sulfur dioxide' 'density' 'pH'\n",
      " 'sulphates' 'alcohol' 'quality']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loading the dataset file\n",
    "import os.path\n",
    "path = \"./Datasets/winequalityN.csv\"\n",
    "if os.path.isfile(path) :\n",
    "    dataset = pd.read_csv(path)\n",
    "else:\n",
    "    dataset = pd.read_csv(\"Neural-networks/\" + path)\n",
    "\n",
    "# Let's take a look at the columns we have in this dataset.\n",
    "print(\"Dataset Columns: {}\\n\".format(dataset.columns.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removing invalid rows**\n",
    "\n",
    "Sometimes, the datasets might be incomplete. This is the case of this dataset and we will remove rows with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 rows containing invalid data removed.\n"
     ]
    }
   ],
   "source": [
    "# Removes rows with invalid values\n",
    "n_rows_b4 = dataset.shape[0]\n",
    "dataset = dataset.dropna(how='any',axis=0)\n",
    "n_rows_c = dataset.shape[0]\n",
    "print(\"{} rows containing invalid data removed.\".format((n_rows_b4-n_rows_c)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Shuffling the dataset**\n",
    "\n",
    "One way to improve the training performance, is to shuffle the dataset before training.\n",
    "\n",
    "When the model learns, it overseers patterns and tries to correlate those patterns to the output. If the occurrence of these patterns are not evenly distributed throughout the dataset, the network might focus only on the patterns that occurs the most. Also, we might have missing inputs or outputs values missing when we separate it into train and test data if the dataset if completely sequentially organized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffles the dataset\n",
    "dataset = shuffle(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Separating into input data and output data**\n",
    "\n",
    "Right now, we have the entire dataset inside the same array. We need to separate it so we can tell our model what are the inputs and outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate into input and outputs of the network\n",
    "predictors = dataset.iloc[:,0:12].values\n",
    "wine_quality = dataset.iloc[:,12].values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Categorical Encoding**\n",
    "\n",
    "The first column of our dataset is \"type\". It can be either \"white\" or \"red\". The network doesn't understand that. It only understands numbers.\n",
    "\n",
    "We could attribute each type with a number. Let's red is 0, and white is 1. But that would not work! The network needs a clearer distinction of what is what.\n",
    "\n",
    "Instead, we are going to give each wine time its own neuron. If it is \"red\", only the first input neuron will be 1. If it \"white\", only the second neuron will be 1.\n",
    "\n",
    "**TODO: The teacher needs to explain the importance of categorical encoding.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cathegory before encoding (10 first): ['white' 'white' 'white' 'red' 'white' 'white' 'red' 'white' 'red' 'white']\n",
      "Cathegory after encoding (10 first):\n",
      "[[0.0 1.0]\n",
      " [0.0 1.0]\n",
      " [0.0 1.0]\n",
      " [1.0 0.0]\n",
      " [0.0 1.0]\n",
      " [0.0 1.0]\n",
      " [1.0 0.0]\n",
      " [0.0 1.0]\n",
      " [1.0 0.0]\n",
      " [0.0 1.0]]\n"
     ]
    }
   ],
   "source": [
    "# Encodes categorized values\n",
    "print(\"Cathegory before encoding (10 first): {}\".format(predictors[0:10,0]))\n",
    "\n",
    "ct = ColumnTransformer([(\"type\", OneHotEncoder(),[0])], remainder=\"passthrough\")\n",
    "predictors = ct.fit_transform(predictors)\n",
    "print(\"Cathegory after encoding (10 first):\\n{}\".format(predictors[0:10,0:2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Separating into train and test datasets**\n",
    "\n",
    "_We are almost there!_\n",
    "\n",
    "We removed invalid data, shuffled, and encoded the dataset.\n",
    "Now we can finally separate our data to train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 6463. Train: 3231. Test: 3232\n"
     ]
    }
   ],
   "source": [
    "train_ratio = 0.5\n",
    "train_index = int(train_ratio*predictors.shape[0])\n",
    "print(\"Total: {0}. Train: {1}. Test: {2}\".format(predictors.shape[0], train_index, predictors.shape[0]-train_index))\n",
    "\n",
    "x_train = predictors[0:train_index]\n",
    "y_train = wine_quality[0:train_index]\n",
    "\n",
    "x_test = predictors[train_index:predictors.shape[0]]\n",
    "y_test = wine_quality[train_index:predictors.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 631,
     "status": "ok",
     "timestamp": 1574499479158,
     "user": {
      "displayName": "Cristian Bortolini Ferreira",
      "photoUrl": "",
      "userId": "01183676841716453456"
     },
     "user_tz": -60
    },
    "id": "SXOX3i2Z91gR",
    "outputId": "958e4f10-795f-41e5-bbd1-baa0fd3d93c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input training data shape: (3231, 13)\n",
      "Example input training data: [0.0 1.0 5.7 0.31 0.28 4.1 0.03 22.0 86.0 0.9906200000000001 3.31 0.38\n",
      " 11.7]\n",
      "Output training data shape: (3231,)\n",
      "Example output training data: 7.0\n",
      "\n",
      "Input test data shape: (3232, 13)\n",
      "Output test data shape: (3232,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Input training data shape:\", x_train.shape)\n",
    "print(\"Example input training data:\",x_train[0])\n",
    "print(\"Output training data shape:\", y_train.shape)\n",
    "print(\"Example output training data:\",y_train[0])\n",
    "\n",
    "print(\"\\nInput test data shape:\", x_test.shape)\n",
    "print(\"Output test data shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8hlS1L-fBTCP"
   },
   "source": [
    "**Building a regression model**\n",
    "\n",
    "It's your time to build a model, train, test, and save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 639,
     "status": "ok",
     "timestamp": 1574499586737,
     "user": {
      "displayName": "Cristian Bortolini Ferreira",
      "photoUrl": "",
      "userId": "01183676841716453456"
     },
     "user_tz": -60
    },
    "id": "moc_VlVk-ebv",
    "outputId": "7951da39-4547-4261-8797-995bf48c2c17",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO: Implement the network.\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    print(\"TODO: Implement the network.\")\n",
    "    model = None\n",
    "    return model\n",
    "\n",
    "net = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "B1-Regression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
