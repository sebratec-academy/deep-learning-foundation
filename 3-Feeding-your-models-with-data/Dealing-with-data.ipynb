{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with data\n",
    "\n",
    "One of the most important parts about deep learning is data. Data is pure raw information, human and machine representation of the observation of the world. Everything can be represented in data, including our literature, arts and science. In this lab, we are going to deal with data, apply some techniques to make our data ready to be applied in a machine learning model, and after that, separate our dataset in training, validation and test datasets and feed that data to a deep learning model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquiring data\n",
    "\n",
    "Before you can even prepare your dataset, you need to acquire one. Unless you already work in a place where you already have that data ready for you, you need to collect it yourself. There are a lot of places where you can acquire data, for example:\n",
    "\n",
    "- [Datasets subreddit](https://www.reddit.com/r/datasets/), a community where you can share, request and discuss about datasets;\n",
    "\n",
    "- [Kaggle](https://www.kaggle.com/), where you can search for a lot of different datasets, jupyter notebooks applying that data, and even engage in competitions;\n",
    "\n",
    "- [Awesome datasets in Github](https://github.com/awesomedata/awesome-public-datasets), a curated list of datasets of a lot of different subjects, hosted in Github.\n",
    "\n",
    "Sometimes, your data will not be easily available, and you will have to get your hands dirty to collect it. While it is beyond the scope of this lab, it is worth to mention that common data collection techniques involve the usage of sensors and [web-scraping](https://en.wikipedia.org/wiki/Web_scraping).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the data\n",
    "\n",
    "Let's say we downloaded the records of a HR department of a company specialized in engineering. This dataset in particular, is about the hires for a software engineering position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# First, let's import our packages as usual.\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dense, Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Columns: ['id' 'years_of_experience' 'interview_score' 'name' 'hired']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Then, let's load our dataset.\n",
    "import os.path\n",
    "path = \"./Datasets/hires.csv\"\n",
    "if os.path.isfile(path) :\n",
    "    dataset = pd.read_csv(path)\n",
    "else:\n",
    "    dataset = pd.read_csv(\"3-Feeding-your-models-with-data/\" + path)\n",
    "\n",
    "# Let's take a look at the columns we have in this dataset.\n",
    "print(\"Dataset Columns: {}\\n\".format(dataset.columns.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we have the following features:\n",
    "\n",
    "- name: the candidate name;\n",
    "- interview_score: a subjective grade that was given to the performance of the candidate in the hiring interview;\n",
    "- years_of_experience: how many years this particular candidate has in the software engineering industry\n",
    "\n",
    "And a class:\n",
    "\n",
    "- hired: which means if the candidate ended up being hired or not;\n",
    "\n",
    "\n",
    "Now, let's take a closer look at our dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>years_of_experience</th>\n",
       "      <th>interview_score</th>\n",
       "      <th>name</th>\n",
       "      <th>hired</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0.54</td>\n",
       "      <td>Stacia Ketchen</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.29</td>\n",
       "      <td>Maryann Rumney</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tristam Oliveti</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.51</td>\n",
       "      <td>Andrea Gianinotti</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.74</td>\n",
       "      <td>Karena Sheran</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>996</td>\n",
       "      <td>6</td>\n",
       "      <td>0.78</td>\n",
       "      <td>Leese Ciccoloi</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>997</td>\n",
       "      <td>5</td>\n",
       "      <td>0.67</td>\n",
       "      <td>Inger Ivashechkin</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>998</td>\n",
       "      <td>5</td>\n",
       "      <td>0.46</td>\n",
       "      <td>Jessalyn Bedingfield</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>999</td>\n",
       "      <td>5</td>\n",
       "      <td>0.89</td>\n",
       "      <td>Deerdre Squibe</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demetri Coxhell</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  years_of_experience  interview_score                  name  hired\n",
       "0       1                   18             0.54        Stacia Ketchen  False\n",
       "1       2                    6             0.29        Maryann Rumney  False\n",
       "2       3                    6              NaN       Tristam Oliveti  False\n",
       "3       4                    2             0.51     Andrea Gianinotti  False\n",
       "4       5                    2             0.74         Karena Sheran  False\n",
       "..    ...                  ...              ...                   ...    ...\n",
       "995   996                    6             0.78        Leese Ciccoloi  False\n",
       "996   997                    5             0.67     Inger Ivashechkin  False\n",
       "997   998                    5             0.46  Jessalyn Bedingfield  False\n",
       "998   999                    5             0.89        Deerdre Squibe   True\n",
       "999  1000                    3              NaN       Demetri Coxhell  False\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see some of the data inside our dataset, simply use the dataset variable.\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some incomplete data inside our dataset. Incomplete data is, most of the times, bad data. So, we need to remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>years_of_experience</th>\n",
       "      <th>interview_score</th>\n",
       "      <th>name</th>\n",
       "      <th>hired</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0.54</td>\n",
       "      <td>Stacia Ketchen</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.29</td>\n",
       "      <td>Maryann Rumney</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.51</td>\n",
       "      <td>Andrea Gianinotti</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.74</td>\n",
       "      <td>Karena Sheran</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0.40</td>\n",
       "      <td>Rafaellle Goodbody</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>995</td>\n",
       "      <td>6</td>\n",
       "      <td>0.67</td>\n",
       "      <td>Alexine Bannister</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>996</td>\n",
       "      <td>6</td>\n",
       "      <td>0.78</td>\n",
       "      <td>Leese Ciccoloi</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>997</td>\n",
       "      <td>5</td>\n",
       "      <td>0.67</td>\n",
       "      <td>Inger Ivashechkin</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>998</td>\n",
       "      <td>5</td>\n",
       "      <td>0.46</td>\n",
       "      <td>Jessalyn Bedingfield</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>999</td>\n",
       "      <td>5</td>\n",
       "      <td>0.89</td>\n",
       "      <td>Deerdre Squibe</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>905 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  years_of_experience  interview_score                  name  hired\n",
       "0      1                   18             0.54        Stacia Ketchen  False\n",
       "1      2                    6             0.29        Maryann Rumney  False\n",
       "3      4                    2             0.51     Andrea Gianinotti  False\n",
       "4      5                    2             0.74         Karena Sheran  False\n",
       "6      7                    9             0.40    Rafaellle Goodbody  False\n",
       "..   ...                  ...              ...                   ...    ...\n",
       "994  995                    6             0.67     Alexine Bannister  False\n",
       "995  996                    6             0.78        Leese Ciccoloi  False\n",
       "996  997                    5             0.67     Inger Ivashechkin  False\n",
       "997  998                    5             0.46  Jessalyn Bedingfield  False\n",
       "998  999                    5             0.89        Deerdre Squibe   True\n",
       "\n",
       "[905 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "# Remove empty rows from dataset\n",
    "for index, data in dataset.iterrows():\n",
    "    if(math.isnan(data.interview_score) or math.isnan(data.years_of_experience)):\n",
    "        dataset.drop(index = index, inplace = True)\n",
    "\n",
    "# Show the updated dataset        \n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to decide what features are important for the problem we are trying to solve. Deciding what features are important, is a key part of machine learning. Remember, bad data equals to bad results, and wrong features are bad data.\n",
    "\n",
    "In this case, the interview score and the years of experience of the candidate are important features, but the name of the candidate is completely irrelevant for our model, so we can just take it out from our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>years_of_experience</th>\n",
       "      <th>interview_score</th>\n",
       "      <th>hired</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0.54</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.29</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.51</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.74</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0.40</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>995</td>\n",
       "      <td>6</td>\n",
       "      <td>0.67</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>996</td>\n",
       "      <td>6</td>\n",
       "      <td>0.78</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>997</td>\n",
       "      <td>5</td>\n",
       "      <td>0.67</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>998</td>\n",
       "      <td>5</td>\n",
       "      <td>0.46</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>999</td>\n",
       "      <td>5</td>\n",
       "      <td>0.89</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>905 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  years_of_experience  interview_score  hired\n",
       "0      1                   18             0.54  False\n",
       "1      2                    6             0.29  False\n",
       "3      4                    2             0.51  False\n",
       "4      5                    2             0.74  False\n",
       "6      7                    9             0.40  False\n",
       "..   ...                  ...              ...    ...\n",
       "994  995                    6             0.67  False\n",
       "995  996                    6             0.78  False\n",
       "996  997                    5             0.67  False\n",
       "997  998                    5             0.46  False\n",
       "998  999                    5             0.89   True\n",
       "\n",
       "[905 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete the column name\n",
    "del dataset['name']\n",
    "# Show our updated dataset\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing that you should have in mind, is that \"True\" and \"False\", doesn't mean anything to a machine. We need to convert that into something that a computer will understand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>years_of_experience</th>\n",
       "      <th>interview_score</th>\n",
       "      <th>hired</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>995</td>\n",
       "      <td>6</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>996</td>\n",
       "      <td>6</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>997</td>\n",
       "      <td>5</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>998</td>\n",
       "      <td>5</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>999</td>\n",
       "      <td>5</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>905 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  years_of_experience  interview_score  hired\n",
       "0      1                   18             0.54      0\n",
       "1      2                    6             0.29      0\n",
       "3      4                    2             0.51      0\n",
       "4      5                    2             0.74      0\n",
       "6      7                    9             0.40      0\n",
       "..   ...                  ...              ...    ...\n",
       "994  995                    6             0.67      0\n",
       "995  996                    6             0.78      0\n",
       "996  997                    5             0.67      0\n",
       "997  998                    5             0.46      0\n",
       "998  999                    5             0.89      1\n",
       "\n",
       "[905 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert true to 1, and false to 0\n",
    "dataset.hired = dataset.hired.astype(int)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc83ceb8470>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's plot the dataset, so we can see who got hired and those who didn't.\n",
    "dataset.plot(kind='scatter', x=\"interview_score\", y=\"years_of_experience\", c=\"hired\", colormap='jet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we could train our network using this dataset. But we could also improve it's representation to make it easier for the network to learn the dataset behavior. The attribute 'years_of_experience' is a value from 1 to 20 (inside our dataset). Let's normalize these values to fit between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts the dataset to numpy arrays\n",
    "X = np.array(dataset[[\"id\",\"years_of_experience\",\"interview_score\"]].astype(float))\n",
    "Y = np.array(dataset[[\"hired\"]])\n",
    "Y = np.ravel(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's separate our dataset into test and training datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the dataset into test and training datasets\n",
    "X_train, X_test, Y_train,Y_test = train_test_split(X, Y, test_size=0.25,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's build a simple classification neural network and train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "data (InputLayer)            (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 250)               1000      \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 1,251\n",
      "Trainable params: 1,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    # Input layer\n",
    "    inputs = Input([3, ], name='data')\n",
    "    # Hidden layers\n",
    "    model = Dense(250, activation='relu')(inputs)\n",
    "    # Output layer\n",
    "    outputs = Dense(1, activation='relu', name='fc3')(model)\n",
    "\n",
    "    # Define the model\n",
    "    model = Model(inputs=[inputs], outputs=outputs)\n",
    "\n",
    "    return model\n",
    "\n",
    "net = build_model()\n",
    "print(net.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3053097345132743"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "def loss_function(y_true, y_pred):\n",
    "    e = K.binary_crossentropy(y_true, y_pred)\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 678 samples, validate on 227 samples\n",
      "Epoch 1/1500\n",
      "678/678 [==============================] - 0s 291us/step - loss: 6.7454 - accuracy: 0.4926 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 2/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 3/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 4/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 5/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 6/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 7/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 8/1500\n",
      "678/678 [==============================] - 0s 133us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 9/1500\n",
      "678/678 [==============================] - 0s 169us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 10/1500\n",
      "678/678 [==============================] - 0s 135us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 11/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 12/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 13/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 14/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 15/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 16/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 17/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 18/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 19/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 20/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 21/1500\n",
      "678/678 [==============================] - 0s 142us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 22/1500\n",
      "678/678 [==============================] - 0s 133us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 23/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 24/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 25/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 26/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 27/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 28/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 29/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 30/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 31/1500\n",
      "678/678 [==============================] - 0s 132us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 32/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 33/1500\n",
      "678/678 [==============================] - 0s 133us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 34/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 35/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 36/1500\n",
      "678/678 [==============================] - 0s 136us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 37/1500\n",
      "678/678 [==============================] - 0s 141us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 38/1500\n",
      "678/678 [==============================] - 0s 142us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 39/1500\n",
      "678/678 [==============================] - 0s 143us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 40/1500\n",
      "678/678 [==============================] - 0s 144us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 41/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 42/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 43/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 44/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 45/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 46/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 47/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 48/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 49/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 50/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 51/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 52/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 53/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 54/1500\n",
      "678/678 [==============================] - 0s 132us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 55/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 56/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 57/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 58/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 59/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 60/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 61/1500\n",
      "678/678 [==============================] - 0s 135us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 62/1500\n",
      "678/678 [==============================] - 0s 144us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 63/1500\n",
      "678/678 [==============================] - 0s 142us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 64/1500\n",
      "678/678 [==============================] - 0s 137us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 65/1500\n",
      "678/678 [==============================] - 0s 147us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 66/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 67/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 68/1500\n",
      "678/678 [==============================] - 0s 132us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 69/1500\n",
      "678/678 [==============================] - 0s 142us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 70/1500\n",
      "678/678 [==============================] - 0s 146us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 71/1500\n",
      "678/678 [==============================] - 0s 149us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 72/1500\n",
      "678/678 [==============================] - 0s 143us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 73/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 74/1500\n",
      "678/678 [==============================] - 0s 136us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 75/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 76/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 77/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 78/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 79/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 80/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 81/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 82/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 83/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 84/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 85/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 86/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 87/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 88/1500\n",
      "678/678 [==============================] - 0s 148us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 89/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 90/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 91/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 92/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 93/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 94/1500\n",
      "678/678 [==============================] - 0s 139us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 95/1500\n",
      "678/678 [==============================] - 0s 132us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 96/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 97/1500\n",
      "678/678 [==============================] - 0s 138us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 98/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 99/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 100/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 101/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 102/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 103/1500\n",
      "678/678 [==============================] - 0s 132us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 104/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 105/1500\n",
      "678/678 [==============================] - 0s 137us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 106/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 107/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 108/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 109/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 110/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 111/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 113/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 114/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 115/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 116/1500\n",
      "678/678 [==============================] - 0s 148us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 117/1500\n",
      "678/678 [==============================] - 0s 136us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 118/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 119/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 120/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 121/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 122/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 123/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 124/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 125/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 126/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 127/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 128/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 129/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 130/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 131/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 132/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 133/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 134/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 135/1500\n",
      "678/678 [==============================] - 0s 132us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 136/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 137/1500\n",
      "678/678 [==============================] - 0s 132us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 138/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 139/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 140/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 141/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 142/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 143/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 144/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 145/1500\n",
      "678/678 [==============================] - 0s 139us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 146/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 147/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 148/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 149/1500\n",
      "678/678 [==============================] - 0s 139us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 150/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 151/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 152/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 153/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 154/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 155/1500\n",
      "678/678 [==============================] - 0s 132us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 156/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 157/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 158/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 159/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 160/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 161/1500\n",
      "678/678 [==============================] - 0s 133us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 162/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 163/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 164/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 165/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 166/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 167/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 168/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 169/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 170/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 171/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 172/1500\n",
      "678/678 [==============================] - 0s 132us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 173/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 174/1500\n",
      "678/678 [==============================] - 0s 136us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 175/1500\n",
      "678/678 [==============================] - 0s 142us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 176/1500\n",
      "678/678 [==============================] - 0s 146us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 177/1500\n",
      "678/678 [==============================] - 0s 140us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 178/1500\n",
      "678/678 [==============================] - 0s 141us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 179/1500\n",
      "678/678 [==============================] - 0s 141us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 180/1500\n",
      "678/678 [==============================] - ETA: 0s - loss: 4.8868 - accuracy: 0.68 - 0s 138us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 181/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 182/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 183/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 184/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 185/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 186/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 187/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 188/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 189/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 190/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 191/1500\n",
      "678/678 [==============================] - 0s 134us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 192/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 193/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 194/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 195/1500\n",
      "678/678 [==============================] - 0s 125us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 196/1500\n",
      "678/678 [==============================] - 0s 125us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 197/1500\n",
      "678/678 [==============================] - 0s 125us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 198/1500\n",
      "678/678 [==============================] - 0s 125us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 199/1500\n",
      "678/678 [==============================] - 0s 140us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 200/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 201/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 202/1500\n",
      "678/678 [==============================] - 0s 161us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 203/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 204/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 205/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 206/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 207/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 208/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 209/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 210/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 211/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 212/1500\n",
      "678/678 [==============================] - 0s 132us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 213/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 214/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 215/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 216/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 217/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 218/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 219/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 220/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 221/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 222/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 223/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 224/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 225/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 226/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 227/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 228/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 229/1500\n",
      "678/678 [==============================] - 0s 125us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 230/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 231/1500\n",
      "678/678 [==============================] - 0s 125us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 232/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 233/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 234/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 235/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 236/1500\n",
      "678/678 [==============================] - 0s 132us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 237/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 238/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 239/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 240/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 241/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 242/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 243/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 244/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 245/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 246/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 247/1500\n",
      "678/678 [==============================] - 0s 132us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 248/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 249/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 250/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 251/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 252/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 253/1500\n",
      "678/678 [==============================] - 0s 142us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 254/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 255/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 256/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 257/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 258/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 259/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 260/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 261/1500\n",
      "678/678 [==============================] - 0s 141us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 262/1500\n",
      "678/678 [==============================] - 0s 140us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 263/1500\n",
      "678/678 [==============================] - 0s 140us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 264/1500\n",
      "678/678 [==============================] - 0s 142us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 265/1500\n",
      "678/678 [==============================] - 0s 147us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 266/1500\n",
      "678/678 [==============================] - 0s 144us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 267/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 268/1500\n",
      "678/678 [==============================] - 0s 134us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 269/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 270/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 271/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 272/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 273/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 274/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 275/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 276/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 277/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 278/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 279/1500\n",
      "678/678 [==============================] - 0s 133us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 280/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 281/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 282/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 283/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 284/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 285/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 286/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 287/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 288/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 289/1500\n",
      "678/678 [==============================] - 0s 125us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 290/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 291/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 292/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 293/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 294/1500\n",
      "678/678 [==============================] - 0s 125us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 295/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 296/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 297/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 298/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 299/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 300/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 301/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 302/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 303/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 304/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 305/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 306/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 307/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 308/1500\n",
      "678/678 [==============================] - 0s 139us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 309/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 310/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 311/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 312/1500\n",
      "678/678 [==============================] - 0s 134us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 313/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 314/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 315/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 316/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 317/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 318/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 319/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 320/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 321/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 322/1500\n",
      "678/678 [==============================] - 0s 137us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 323/1500\n",
      "678/678 [==============================] - 0s 133us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 324/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 325/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 326/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 327/1500\n",
      "678/678 [==============================] - 0s 125us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 328/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 329/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 330/1500\n",
      "678/678 [==============================] - 0s 134us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 331/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 332/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 333/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 334/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 335/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 336/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 337/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 338/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 339/1500\n",
      "678/678 [==============================] - 0s 125us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 340/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 341/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 342/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 343/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 344/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 345/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 346/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 347/1500\n",
      "678/678 [==============================] - 0s 125us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 348/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 349/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 350/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 351/1500\n",
      "678/678 [==============================] - 0s 125us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 352/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 353/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 354/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 355/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 356/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 357/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 358/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 359/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 360/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 361/1500\n",
      "678/678 [==============================] - 0s 150us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 362/1500\n",
      "678/678 [==============================] - 0s 133us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 363/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 364/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 365/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 366/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 367/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 368/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 369/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 370/1500\n",
      "678/678 [==============================] - 0s 137us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 371/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 372/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 373/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 374/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 375/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 376/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 377/1500\n",
      "678/678 [==============================] - 0s 132us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 378/1500\n",
      "678/678 [==============================] - 0s 125us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 379/1500\n",
      "678/678 [==============================] - 0s 125us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 380/1500\n",
      "678/678 [==============================] - 0s 136us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 381/1500\n",
      "678/678 [==============================] - 0s 125us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 382/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 383/1500\n",
      "678/678 [==============================] - 0s 125us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 384/1500\n",
      "678/678 [==============================] - 0s 125us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 385/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 386/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 387/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 388/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 389/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 390/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 391/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 392/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 393/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 394/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 395/1500\n",
      "678/678 [==============================] - 0s 134us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 396/1500\n",
      "678/678 [==============================] - 0s 139us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 397/1500\n",
      "678/678 [==============================] - 0s 133us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 398/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 399/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 400/1500\n",
      "678/678 [==============================] - 0s 136us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 401/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 402/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 403/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 404/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 405/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 406/1500\n",
      "678/678 [==============================] - 0s 137us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 407/1500\n",
      "678/678 [==============================] - 0s 135us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 408/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 409/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 410/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 411/1500\n",
      "678/678 [==============================] - 0s 150us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 412/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 413/1500\n",
      "678/678 [==============================] - 0s 125us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 414/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 415/1500\n",
      "678/678 [==============================] - 0s 137us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 416/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 417/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 418/1500\n",
      "678/678 [==============================] - 0s 132us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 419/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 420/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 421/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 422/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 423/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 424/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 425/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 426/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 427/1500\n",
      "678/678 [==============================] - 0s 132us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 428/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 429/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 430/1500\n",
      "678/678 [==============================] - 0s 133us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 431/1500\n",
      "678/678 [==============================] - 0s 132us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 432/1500\n",
      "678/678 [==============================] - 0s 133us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 433/1500\n",
      "678/678 [==============================] - 0s 136us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 434/1500\n",
      "678/678 [==============================] - 0s 133us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 435/1500\n",
      "678/678 [==============================] - 0s 132us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 436/1500\n",
      "678/678 [==============================] - 0s 132us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 437/1500\n",
      "678/678 [==============================] - 0s 135us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 438/1500\n",
      "678/678 [==============================] - 0s 135us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 439/1500\n",
      "678/678 [==============================] - 0s 140us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 440/1500\n",
      "678/678 [==============================] - 0s 134us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 441/1500\n",
      "678/678 [==============================] - 0s 137us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 442/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678/678 [==============================] - 0s 137us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 443/1500\n",
      "678/678 [==============================] - 0s 137us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 444/1500\n",
      "678/678 [==============================] - 0s 138us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 445/1500\n",
      "678/678 [==============================] - 0s 132us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 446/1500\n",
      "678/678 [==============================] - 0s 134us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 447/1500\n",
      "678/678 [==============================] - 0s 135us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 448/1500\n",
      "678/678 [==============================] - 0s 134us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 449/1500\n",
      "678/678 [==============================] - 0s 134us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 450/1500\n",
      "678/678 [==============================] - 0s 135us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 451/1500\n",
      "678/678 [==============================] - 0s 139us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 452/1500\n",
      "678/678 [==============================] - 0s 138us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 453/1500\n",
      "678/678 [==============================] - 0s 132us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 454/1500\n",
      "678/678 [==============================] - 0s 132us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 455/1500\n",
      "678/678 [==============================] - 0s 132us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 456/1500\n",
      "678/678 [==============================] - 0s 134us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 457/1500\n",
      "678/678 [==============================] - 0s 135us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 458/1500\n",
      "678/678 [==============================] - 0s 154us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 459/1500\n",
      "678/678 [==============================] - 0s 147us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 460/1500\n",
      "678/678 [==============================] - 0s 145us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 461/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 462/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 463/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 464/1500\n",
      "678/678 [==============================] - 0s 138us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 465/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 466/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 467/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 468/1500\n",
      "678/678 [==============================] - 0s 144us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 469/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 470/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 471/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 472/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 473/1500\n",
      "678/678 [==============================] - 0s 125us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 474/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 475/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 476/1500\n",
      "678/678 [==============================] - 0s 136us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 477/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 478/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 479/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 480/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 481/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 482/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 483/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 484/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 485/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 486/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 487/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 488/1500\n",
      "678/678 [==============================] - 0s 136us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 489/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 490/1500\n",
      "678/678 [==============================] - 0s 133us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 491/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 492/1500\n",
      "678/678 [==============================] - 0s 132us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 493/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 494/1500\n",
      "678/678 [==============================] - 0s 134us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 495/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 496/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 497/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 498/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 499/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 500/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 501/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 502/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 503/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 504/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 505/1500\n",
      "678/678 [==============================] - 0s 134us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 506/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 507/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 508/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 509/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 510/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 511/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 512/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 513/1500\n",
      "678/678 [==============================] - 0s 135us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 514/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 515/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 516/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 517/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 518/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 519/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 520/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 521/1500\n",
      "678/678 [==============================] - 0s 132us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 522/1500\n",
      "678/678 [==============================] - 0s 149us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 523/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 524/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 525/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 526/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 527/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 528/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 529/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 530/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 531/1500\n",
      "678/678 [==============================] - 0s 135us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 532/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 533/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 534/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 535/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 536/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 537/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 538/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 539/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 540/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 541/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 542/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 543/1500\n",
      "678/678 [==============================] - 0s 125us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 544/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 545/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 546/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 547/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 548/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 549/1500\n",
      "678/678 [==============================] - 0s 137us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 550/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 551/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 552/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 553/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 554/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 555/1500\n",
      "678/678 [==============================] - 0s 135us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 556/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 557/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 558/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 559/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 560/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 561/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 562/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 563/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 564/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 565/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 566/1500\n",
      "678/678 [==============================] - 0s 149us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 567/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 568/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 569/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 570/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 571/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 572/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 573/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 574/1500\n",
      "678/678 [==============================] - 0s 135us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 575/1500\n",
      "678/678 [==============================] - 0s 149us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 576/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 577/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 578/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 579/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 580/1500\n",
      "678/678 [==============================] - 0s 137us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 581/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 582/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 583/1500\n",
      "678/678 [==============================] - 0s 223us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 584/1500\n",
      "678/678 [==============================] - 0s 139us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 585/1500\n",
      "678/678 [==============================] - 0s 124us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 586/1500\n",
      "678/678 [==============================] - 0s 135us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 587/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 588/1500\n",
      "678/678 [==============================] - 0s 144us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 589/1500\n",
      "678/678 [==============================] - 0s 132us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 590/1500\n",
      "678/678 [==============================] - 0s 135us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 591/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 592/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 593/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 594/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 595/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 596/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 597/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 598/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 599/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 600/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 601/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 602/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 603/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 604/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 605/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 606/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 607/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 608/1500\n",
      "678/678 [==============================] - 0s 142us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 609/1500\n",
      "678/678 [==============================] - 0s 141us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 610/1500\n",
      "678/678 [==============================] - 0s 132us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 611/1500\n",
      "678/678 [==============================] - 0s 146us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 612/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 613/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 614/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 615/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 616/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 617/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 618/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 619/1500\n",
      "678/678 [==============================] - 0s 134us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 620/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 621/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 622/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 623/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 624/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 625/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 626/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 627/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 628/1500\n",
      "678/678 [==============================] - 0s 144us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 629/1500\n",
      "678/678 [==============================] - 0s 132us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 630/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 631/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 632/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 633/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 634/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 635/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 636/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 637/1500\n",
      "678/678 [==============================] - 0s 133us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 638/1500\n",
      "678/678 [==============================] - 0s 136us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 639/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 640/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 641/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 642/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 643/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 644/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 645/1500\n",
      "678/678 [==============================] - 0s 125us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 646/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 647/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 648/1500\n",
      "678/678 [==============================] - 0s 125us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 649/1500\n",
      "678/678 [==============================] - 0s 125us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 650/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 651/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 652/1500\n",
      "678/678 [==============================] - 0s 154us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 653/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 654/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 655/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 656/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 657/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 658/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 659/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 660/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 661/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 662/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 663/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 664/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 665/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 666/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 667/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 668/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 669/1500\n",
      "678/678 [==============================] - 0s 124us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 670/1500\n",
      "678/678 [==============================] - 0s 125us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 671/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 672/1500\n",
      "678/678 [==============================] - 0s 124us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 673/1500\n",
      "678/678 [==============================] - 0s 125us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 674/1500\n",
      "678/678 [==============================] - 0s 133us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 675/1500\n",
      "678/678 [==============================] - 0s 133us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 676/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 677/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 678/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 679/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 680/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 681/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 682/1500\n",
      "678/678 [==============================] - 0s 140us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 683/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 684/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 685/1500\n",
      "678/678 [==============================] - 0s 132us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 686/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 687/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 688/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 689/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 690/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 691/1500\n",
      "678/678 [==============================] - 0s 136us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 692/1500\n",
      "678/678 [==============================] - 0s 140us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 693/1500\n",
      "678/678 [==============================] - 0s 139us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 694/1500\n",
      "678/678 [==============================] - 0s 144us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 695/1500\n",
      "678/678 [==============================] - 0s 141us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 696/1500\n",
      "678/678 [==============================] - 0s 139us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 697/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 698/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 699/1500\n",
      "678/678 [==============================] - 0s 136us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 700/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 701/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 702/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 703/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 704/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 705/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 706/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 707/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 708/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 709/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 710/1500\n",
      "678/678 [==============================] - 0s 134us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 711/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 712/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 713/1500\n",
      "678/678 [==============================] - 0s 125us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 714/1500\n",
      "678/678 [==============================] - 0s 125us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 715/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 716/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 717/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678/678 [==============================] - 0s 125us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 718/1500\n",
      "678/678 [==============================] - 0s 139us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 719/1500\n",
      "678/678 [==============================] - 0s 134us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 720/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 721/1500\n",
      "678/678 [==============================] - 0s 137us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 722/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 723/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 724/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 725/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 726/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 727/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 728/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 729/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 730/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 731/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 732/1500\n",
      "678/678 [==============================] - 0s 151us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 733/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 734/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 735/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 736/1500\n",
      "678/678 [==============================] - 0s 145us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 737/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 738/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 739/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 740/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 741/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 742/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 743/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 744/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 745/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 746/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 747/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 748/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 749/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 750/1500\n",
      "678/678 [==============================] - 0s 134us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 751/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 752/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 753/1500\n",
      "678/678 [==============================] - 0s 141us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 754/1500\n",
      "678/678 [==============================] - ETA: 0s - loss: 4.7206 - accuracy: 0.69 - 0s 145us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 755/1500\n",
      "678/678 [==============================] - 0s 141us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 756/1500\n",
      "678/678 [==============================] - 0s 141us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 757/1500\n",
      "678/678 [==============================] - 0s 140us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 758/1500\n",
      "678/678 [==============================] - 0s 143us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 759/1500\n",
      "678/678 [==============================] - 0s 141us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 760/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 761/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 762/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 763/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 764/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 765/1500\n",
      "678/678 [==============================] - 0s 125us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 766/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 767/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 768/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 769/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 770/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 771/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 772/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 773/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 774/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 775/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 776/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 777/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 778/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 779/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 780/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 781/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 782/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 783/1500\n",
      "678/678 [==============================] - 0s 139us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 784/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 785/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 786/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 787/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 788/1500\n",
      "678/678 [==============================] - 0s 140us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 789/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 790/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 791/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 792/1500\n",
      "678/678 [==============================] - 0s 133us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 793/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 794/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 795/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 796/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 797/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 798/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 799/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 800/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 801/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 802/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 803/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 804/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 805/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 806/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 807/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 808/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 809/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 810/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 811/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 812/1500\n",
      "678/678 [==============================] - 0s 133us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 813/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 814/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 815/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 816/1500\n",
      "678/678 [==============================] - 0s 135us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 817/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 818/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 819/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 820/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 821/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 822/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 823/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 824/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 825/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 826/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 827/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 828/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 829/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 830/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 831/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 832/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 833/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 834/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 835/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 836/1500\n",
      "678/678 [==============================] - 0s 133us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 837/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 838/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 839/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 840/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 841/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 842/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 843/1500\n",
      "678/678 [==============================] - 0s 125us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 844/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 845/1500\n",
      "678/678 [==============================] - 0s 147us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 846/1500\n",
      "678/678 [==============================] - 0s 132us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 847/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 848/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 849/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 850/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 851/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 852/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 853/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 854/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 855/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 856/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 857/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 858/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 859/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 860/1500\n",
      "678/678 [==============================] - 0s 141us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 861/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 862/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 863/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 864/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 865/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 866/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 867/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 868/1500\n",
      "678/678 [==============================] - 0s 132us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 869/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 870/1500\n",
      "678/678 [==============================] - 0s 135us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 871/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 872/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 873/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 874/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 875/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 876/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 877/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 878/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 879/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 880/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 881/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 882/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 883/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 884/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 885/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 886/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 887/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 888/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 889/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 890/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 891/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 892/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 893/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 894/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 895/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 896/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 897/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 898/1500\n",
      "678/678 [==============================] - 0s 144us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 899/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 900/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 901/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 902/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 903/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 904/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 905/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 906/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 907/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 908/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 909/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 910/1500\n",
      "678/678 [==============================] - 0s 135us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 911/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 912/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 913/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 914/1500\n",
      "678/678 [==============================] - 0s 132us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 915/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 916/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 917/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 918/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 919/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 920/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 921/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 922/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 923/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 924/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 925/1500\n",
      "678/678 [==============================] - 0s 140us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 926/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 927/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 928/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 929/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 930/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 931/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 932/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 933/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 934/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 935/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 936/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 937/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 938/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 939/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 940/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 941/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 942/1500\n",
      "678/678 [==============================] - 0s 134us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 943/1500\n",
      "678/678 [==============================] - 0s 132us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 944/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 945/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 946/1500\n",
      "678/678 [==============================] - 0s 132us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 947/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 948/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 949/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 950/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 951/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 952/1500\n",
      "678/678 [==============================] - 0s 146us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 953/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 954/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 955/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 956/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 957/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 958/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 959/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 960/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 961/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 962/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 963/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 964/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 965/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 966/1500\n",
      "678/678 [==============================] - 0s 133us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 967/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 968/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 969/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 970/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 971/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 972/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 973/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 974/1500\n",
      "678/678 [==============================] - 0s 134us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 975/1500\n",
      "678/678 [==============================] - 0s 134us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 976/1500\n",
      "678/678 [==============================] - 0s 138us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 977/1500\n",
      "678/678 [==============================] - 0s 137us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 978/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 979/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 980/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 981/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 982/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 983/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 984/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 985/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 986/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 987/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 988/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 989/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 990/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 991/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 992/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 993/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 994/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 995/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 996/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 997/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 998/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 999/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1000/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1001/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1002/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1003/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1004/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1005/1500\n",
      "678/678 [==============================] - 0s 138us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1006/1500\n",
      "678/678 [==============================] - 0s 144us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1007/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1008/1500\n",
      "678/678 [==============================] - 0s 133us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1009/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1010/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1011/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1012/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1013/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1014/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1015/1500\n",
      "678/678 [==============================] - 0s 133us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1016/1500\n",
      "678/678 [==============================] - 0s 125us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1017/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1018/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1019/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1020/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1021/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1022/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1023/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1024/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1025/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1026/1500\n",
      "678/678 [==============================] - 0s 138us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1027/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1028/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1029/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1030/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1031/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1032/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1033/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1034/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1035/1500\n",
      "678/678 [==============================] - 0s 125us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1036/1500\n",
      "678/678 [==============================] - 0s 125us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1037/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1038/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1039/1500\n",
      "678/678 [==============================] - 0s 141us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1040/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1041/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1042/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1043/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1044/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1045/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1046/1500\n",
      "678/678 [==============================] - 0s 137us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1047/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1048/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1049/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1050/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1051/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1052/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1053/1500\n",
      "678/678 [==============================] - 0s 135us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1054/1500\n",
      "678/678 [==============================] - 0s 138us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1055/1500\n",
      "678/678 [==============================] - 0s 125us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1056/1500\n",
      "678/678 [==============================] - 0s 159us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1057/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1058/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1059/1500\n",
      "678/678 [==============================] - 0s 125us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1060/1500\n",
      "678/678 [==============================] - 0s 141us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1061/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1062/1500\n",
      "678/678 [==============================] - 0s 132us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1063/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1064/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1065/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1066/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1067/1500\n",
      "678/678 [==============================] - 0s 125us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1068/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1069/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1070/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1071/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1072/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1073/1500\n",
      "678/678 [==============================] - 0s 138us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1074/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1075/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1076/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1077/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1078/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1079/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1080/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1081/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1082/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1083/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1084/1500\n",
      "678/678 [==============================] - 0s 134us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1085/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1086/1500\n",
      "678/678 [==============================] - 0s 132us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1087/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1088/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1089/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1090/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1091/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1092/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1093/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1094/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1095/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1096/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1097/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1098/1500\n",
      "678/678 [==============================] - 0s 132us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1099/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1100/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1101/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1102/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1103/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1104/1500\n",
      "678/678 [==============================] - 0s 132us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1105/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1106/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1107/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1108/1500\n",
      "678/678 [==============================] - 0s 132us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1109/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1110/1500\n",
      "678/678 [==============================] - 0s 140us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1111/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1112/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1113/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1114/1500\n",
      "678/678 [==============================] - 0s 144us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1115/1500\n",
      "678/678 [==============================] - 0s 134us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1116/1500\n",
      "678/678 [==============================] - 0s 138us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1117/1500\n",
      "678/678 [==============================] - 0s 132us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1118/1500\n",
      "678/678 [==============================] - 0s 132us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1119/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1120/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1121/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1122/1500\n",
      "678/678 [==============================] - 0s 139us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1123/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1124/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1125/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1126/1500\n",
      "678/678 [==============================] - 0s 133us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1127/1500\n",
      "678/678 [==============================] - 0s 138us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1128/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1129/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1130/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1131/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1132/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1133/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1134/1500\n",
      "678/678 [==============================] - 0s 138us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1135/1500\n",
      "678/678 [==============================] - 0s 134us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1136/1500\n",
      "678/678 [==============================] - 0s 136us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1137/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1138/1500\n",
      "678/678 [==============================] - 0s 132us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1139/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1140/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1141/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1142/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1143/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1144/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1145/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1146/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1147/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1148/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1149/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1150/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1151/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1152/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1153/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1154/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1155/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1156/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1157/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1158/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1159/1500\n",
      "678/678 [==============================] - 0s 138us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1160/1500\n",
      "678/678 [==============================] - 0s 125us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1161/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1162/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1163/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1164/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1165/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1166/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1167/1500\n",
      "678/678 [==============================] - 0s 148us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1168/1500\n",
      "678/678 [==============================] - 0s 132us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1169/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1170/1500\n",
      "678/678 [==============================] - 0s 141us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1171/1500\n",
      "678/678 [==============================] - 0s 137us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1172/1500\n",
      "678/678 [==============================] - 0s 132us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1173/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1174/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1175/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1176/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1177/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1178/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1179/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1180/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1181/1500\n",
      "678/678 [==============================] - 0s 125us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1182/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1183/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1184/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1185/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1186/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1187/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1188/1500\n",
      "678/678 [==============================] - 0s 125us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1189/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1190/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1191/1500\n",
      "678/678 [==============================] - 0s 133us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1192/1500\n",
      "678/678 [==============================] - 0s 133us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1193/1500\n",
      "678/678 [==============================] - 0s 133us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1194/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1195/1500\n",
      "678/678 [==============================] - 0s 142us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1196/1500\n",
      "678/678 [==============================] - 0s 134us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1197/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1198/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1199/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1200/1500\n",
      "678/678 [==============================] - 0s 135us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1201/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1202/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1203/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1204/1500\n",
      "678/678 [==============================] - 0s 133us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1205/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1206/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1207/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1208/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1209/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1210/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1211/1500\n",
      "678/678 [==============================] - 0s 136us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1212/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1213/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1214/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1215/1500\n",
      "678/678 [==============================] - 0s 133us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1216/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1217/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1218/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1219/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1220/1500\n",
      "678/678 [==============================] - 0s 149us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1221/1500\n",
      "678/678 [==============================] - 0s 128us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1222/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1223/1500\n",
      "678/678 [==============================] - 0s 131us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1224/1500\n",
      "678/678 [==============================] - 0s 130us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1225/1500\n",
      "678/678 [==============================] - 0s 129us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1226/1500\n",
      "678/678 [==============================] - 0s 127us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1227/1500\n",
      "678/678 [==============================] - 0s 126us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1228/1500\n",
      "678/678 [==============================] - 0s 161us/step - loss: 4.7094 - accuracy: 0.6947 - val_loss: 4.5527 - val_accuracy: 0.7048\n",
      "Epoch 1229/1500\n",
      "  8/678 [..............................] - ETA: 0s - loss: 3.8562 - accuracy: 0.7500"
     ]
    }
   ],
   "source": [
    "from keras import metrics\n",
    "net.compile(optimizer='sgd',\n",
    "              loss=loss_function,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = net.fit(X_train,\n",
    "        Y_train,\n",
    "        validation_data=(X_test, Y_test),\n",
    "        epochs=1500,\n",
    "        batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_v = list(history.history.keys())\n",
    "print(metric_v)\n",
    "\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(history.history[metric_v[2]])\n",
    "plt.plot(history.history[metric_v[0]])\n",
    "plt.legend(['Train','Test'])\n",
    "plt.show()\n",
    "\n",
    "plt.title('Precision')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Precision')\n",
    "plt.plot(history.history[metric_v[3]])\n",
    "plt.plot(history.history[metric_v[1]])\n",
    "plt.legend(['Train','Test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model performance\n",
    "_, train_a = net.evaluate(X_train,  Y_train, verbose=2)\n",
    "print('\\nTrain accuracy:', train_a)\n",
    "\n",
    "_, test_a = net.evaluate(X_test,  Y_test, verbose=2)\n",
    "print('\\nTest accuracy:', test_a)\n",
    "\n",
    "# Predict if a new candidate with interview score of 0.6 and 15 years of experience will be hired\n",
    "input = np.array([[0,0.5,0.5]])\n",
    "prediction = net.predict(input)\n",
    "for index, predict in enumerate(prediction):\n",
    "    print(\"Candidate has {:.2f}% chance to be hired\".format(predict[0]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can generate a map covering all the possible predictions to see how our model behaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a classification map\n",
    "N = 60\n",
    "\n",
    "years_range = (X[:,1].min(), X[:,1].max())\n",
    "scores_range = (X[:,2].min()-.1, X[:,2].max()+.1)\n",
    "\n",
    "linear_years = np.linspace(years_range[0], years_range[1], N)\n",
    "linear_scores = np.linspace(scores_range[0], scores_range[1], N)\n",
    "\n",
    "prediction_map = np.array([net.predict(np.array([[0,i,j]])) for j in linear_scores for i in linear_years]).reshape(N, N).T\n",
    "\n",
    "# Plots our test dataset on top of our prediction map\n",
    "plt.imshow(prediction_map,\n",
    "           interpolation='bilinear',\n",
    "           extent=[\n",
    "               scores_range[0], scores_range[1],years_range[0], years_range[1], \n",
    "           ],\n",
    "           aspect='auto' , origin='lower')\n",
    "plt.scatter(np.array(X_train)[:,2], np.array(X_train)[:,1], 40, Y_train, edgecolors='w')\n",
    "plt.show()\n",
    "\n",
    "# Plots our test dataset on top of our prediction map\n",
    "plt.imshow(prediction_map,\n",
    "           interpolation='bilinear',\n",
    "           extent=[\n",
    "               scores_range[0], scores_range[1],years_range[0], years_range[1], \n",
    "           ],\n",
    "           aspect='auto' , origin='lower')\n",
    "plt.scatter(np.array(X_test)[:,2], np.array(X_test)[:,1], 40, Y_test, edgecolors='w')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
